{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb7ad851-864f-4b01-944d-ab88d7805e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e09bb6e5-96c4-431e-9719-8c3a5a1b59db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train and test file\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c97793f-7c90-4441-9194-39ea54d97691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14545 entries, 0 to 14544\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   user_reputation  14545 non-null  int64 \n",
      " 1   reply_count      14545 non-null  int64 \n",
      " 2   thumbs_up        14545 non-null  int64 \n",
      " 3   thumbs_down      14545 non-null  int64 \n",
      " 4   best_score       14545 non-null  int64 \n",
      " 5   text             14543 non-null  object\n",
      " 6   stars            14545 non-null  int64 \n",
      "dtypes: int64(6), object(1)\n",
      "memory usage: 795.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# visualize train_data\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7a64b9a-183f-46a3-bd28-c337510024bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_reputation</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>thumbs_up</th>\n",
       "      <th>thumbs_down</th>\n",
       "      <th>best_score</th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>Tasty!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>As soon as I saw this on the cover of the maga...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>This recipe is great! I have never made bread ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>261</td>\n",
       "      <td>@Sarah (from Dec. 16, 2019): What the recipe d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>This was absolutely delish!   My whole family ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_reputation  reply_count  thumbs_up  thumbs_down  best_score  \\\n",
       "0                1            0          0            0         100   \n",
       "1                1            0          0            0         100   \n",
       "2                1            0          0            0         100   \n",
       "3               10            0          5            2         261   \n",
       "4                1            0          0            0         100   \n",
       "\n",
       "                                                text  stars  \n",
       "0                                             Tasty!      5  \n",
       "1  As soon as I saw this on the cover of the maga...      5  \n",
       "2  This recipe is great! I have never made bread ...      5  \n",
       "3  @Sarah (from Dec. 16, 2019): What the recipe d...      0  \n",
       "4  This was absolutely delish!   My whole family ...      5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1de25a49-dd49-4037-a5db-c0c41f6ef69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_reputation</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>thumbs_up</th>\n",
       "      <th>thumbs_down</th>\n",
       "      <th>best_score</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14545.000000</td>\n",
       "      <td>14545.000000</td>\n",
       "      <td>14545.000000</td>\n",
       "      <td>14545.000000</td>\n",
       "      <td>14545.000000</td>\n",
       "      <td>14545.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.165211</td>\n",
       "      <td>0.014163</td>\n",
       "      <td>1.102509</td>\n",
       "      <td>0.548230</td>\n",
       "      <td>153.924579</td>\n",
       "      <td>4.285115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.950558</td>\n",
       "      <td>0.134494</td>\n",
       "      <td>4.177282</td>\n",
       "      <td>3.373137</td>\n",
       "      <td>142.637031</td>\n",
       "      <td>1.546951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>520.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>946.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_reputation   reply_count     thumbs_up   thumbs_down  \\\n",
       "count     14545.000000  14545.000000  14545.000000  14545.000000   \n",
       "mean          2.165211      0.014163      1.102509      0.548230   \n",
       "std           9.950558      0.134494      4.177282      3.373137   \n",
       "min           0.000000      0.000000      0.000000      0.000000   \n",
       "25%           1.000000      0.000000      0.000000      0.000000   \n",
       "50%           1.000000      0.000000      0.000000      0.000000   \n",
       "75%           1.000000      0.000000      0.000000      0.000000   \n",
       "max         520.000000      3.000000     80.000000    122.000000   \n",
       "\n",
       "         best_score         stars  \n",
       "count  14545.000000  14545.000000  \n",
       "mean     153.924579      4.285115  \n",
       "std      142.637031      1.546951  \n",
       "min        0.000000      0.000000  \n",
       "25%      100.000000      5.000000  \n",
       "50%      100.000000      5.000000  \n",
       "75%      100.000000      5.000000  \n",
       "max      946.000000      5.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f394c63c-e2e0-4232-8517-e71976588bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3637 entries, 0 to 3636\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   user_reputation  3637 non-null   int64 \n",
      " 1   reply_count      3637 non-null   int64 \n",
      " 2   thumbs_up        3637 non-null   int64 \n",
      " 3   thumbs_down      3637 non-null   int64 \n",
      " 4   best_score       3637 non-null   int64 \n",
      " 5   text             3637 non-null   object\n",
      " 6   stars            3637 non-null   int64 \n",
      "dtypes: int64(6), object(1)\n",
      "memory usage: 199.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# visualize train_data, same stpes as train_data\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da05a1f1-d4cf-4bb7-bb71-d5d0bf7d71b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_reputation</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>thumbs_up</th>\n",
       "      <th>thumbs_down</th>\n",
       "      <th>best_score</th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>i am on the fence with this one it was alright...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>I just found this recipe online after losing i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>8</td>\n",
       "      <td>873</td>\n",
       "      <td>We have made this recipe several times and enj...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>I made the exact recipe as is and it is wonder...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>Have been on the hunt for the best Stuffed Pep...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_reputation  reply_count  thumbs_up  thumbs_down  best_score  \\\n",
       "0                1            0          0            0         100   \n",
       "1                1            0          0            0         100   \n",
       "2                1            0         57            8         873   \n",
       "3                1            0          0            0         100   \n",
       "4                1            0          0            1         100   \n",
       "\n",
       "                                                text  stars  \n",
       "0  i am on the fence with this one it was alright...      3  \n",
       "1  I just found this recipe online after losing i...      0  \n",
       "2  We have made this recipe several times and enj...      0  \n",
       "3  I made the exact recipe as is and it is wonder...      5  \n",
       "4  Have been on the hunt for the best Stuffed Pep...      5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3696d9e-71f8-4f4c-91e0-4ea9afbede6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_reputation</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>thumbs_up</th>\n",
       "      <th>thumbs_down</th>\n",
       "      <th>best_score</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3637.000000</td>\n",
       "      <td>3637.000000</td>\n",
       "      <td>3637.000000</td>\n",
       "      <td>3637.000000</td>\n",
       "      <td>3637.000000</td>\n",
       "      <td>3637.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.137201</td>\n",
       "      <td>0.016497</td>\n",
       "      <td>1.036294</td>\n",
       "      <td>0.553753</td>\n",
       "      <td>150.113005</td>\n",
       "      <td>4.303547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.268407</td>\n",
       "      <td>0.151096</td>\n",
       "      <td>4.294738</td>\n",
       "      <td>3.834041</td>\n",
       "      <td>134.624598</td>\n",
       "      <td>1.536222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>510.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>922.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_reputation  reply_count    thumbs_up  thumbs_down   best_score  \\\n",
       "count      3637.000000  3637.000000  3637.000000  3637.000000  3637.000000   \n",
       "mean          2.137201     0.016497     1.036294     0.553753   150.113005   \n",
       "std          10.268407     0.151096     4.294738     3.834041   134.624598   \n",
       "min           0.000000     0.000000     0.000000     0.000000     4.000000   \n",
       "25%           1.000000     0.000000     0.000000     0.000000   100.000000   \n",
       "50%           1.000000     0.000000     0.000000     0.000000   100.000000   \n",
       "75%           1.000000     0.000000     0.000000     0.000000   100.000000   \n",
       "max         510.000000     3.000000   106.000000   126.000000   922.000000   \n",
       "\n",
       "             stars  \n",
       "count  3637.000000  \n",
       "mean      4.303547  \n",
       "std       1.536222  \n",
       "min       0.000000  \n",
       "25%       5.000000  \n",
       "50%       5.000000  \n",
       "75%       5.000000  \n",
       "max       5.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08eb6be1-14ba-4231-97ed-ad60ea3b7cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since a score of 0 denoting an absence of rating, we remove all the zero in stars col for train and test dataset\n",
    "train_data = train_data[train_data['stars'] !=0] \n",
    "test_data = test_data[test_data['stars'] !=0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30ee04fe-6436-4882-8fd0-4f7d47d4a602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_reputation</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>thumbs_up</th>\n",
       "      <th>thumbs_down</th>\n",
       "      <th>best_score</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user_reputation</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008163</td>\n",
       "      <td>0.060865</td>\n",
       "      <td>0.026532</td>\n",
       "      <td>0.146126</td>\n",
       "      <td>0.003879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reply_count</th>\n",
       "      <td>0.008163</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.185090</td>\n",
       "      <td>0.291853</td>\n",
       "      <td>0.179159</td>\n",
       "      <td>-0.113347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thumbs_up</th>\n",
       "      <td>0.060865</td>\n",
       "      <td>0.185090</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.401592</td>\n",
       "      <td>0.692462</td>\n",
       "      <td>-0.006781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thumbs_down</th>\n",
       "      <td>0.026532</td>\n",
       "      <td>0.291853</td>\n",
       "      <td>0.401592</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.230069</td>\n",
       "      <td>-0.245342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best_score</th>\n",
       "      <td>0.146126</td>\n",
       "      <td>0.179159</td>\n",
       "      <td>0.692462</td>\n",
       "      <td>0.230069</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stars</th>\n",
       "      <td>0.003879</td>\n",
       "      <td>-0.113347</td>\n",
       "      <td>-0.006781</td>\n",
       "      <td>-0.245342</td>\n",
       "      <td>0.019012</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_reputation  reply_count  thumbs_up  thumbs_down  \\\n",
       "user_reputation         1.000000     0.008163   0.060865     0.026532   \n",
       "reply_count             0.008163     1.000000   0.185090     0.291853   \n",
       "thumbs_up               0.060865     0.185090   1.000000     0.401592   \n",
       "thumbs_down             0.026532     0.291853   0.401592     1.000000   \n",
       "best_score              0.146126     0.179159   0.692462     0.230069   \n",
       "stars                   0.003879    -0.113347  -0.006781    -0.245342   \n",
       "\n",
       "                 best_score     stars  \n",
       "user_reputation    0.146126  0.003879  \n",
       "reply_count        0.179159 -0.113347  \n",
       "thumbs_up          0.692462 -0.006781  \n",
       "thumbs_down        0.230069 -0.245342  \n",
       "best_score         1.000000  0.019012  \n",
       "stars              0.019012  1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check correlation for each numeric feactures\n",
    "numeric_train_data = train_data[['user_reputation', 'reply_count', 'thumbs_up', 'thumbs_down', 'best_score', 'stars']]\n",
    "numeric_train_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d0c23d-e05c-4e9b-87ef-825e91ef9af4",
   "metadata": {},
   "source": [
    "# From the correlation table, scores around above 0.75 or below -0.75 are identified as having a strong correlation. However, in this table, all the scores are below 0.75 or above -0.75, which indicates that these features have a low correlation. We must consider another approach to solve this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee9025f2-297d-4d78-ae8e-c63b667d385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same steps for test data\n",
    "test_data['text'] = test_data['text'].str.lower()\n",
    "test_data['text'] = test_data['text'].str.replace('[^\\w\\s]', '', regex=True)\n",
    "train_data['text'] = train_data['text'].str.lower()\n",
    "train_data['text'] = train_data['text'].str.replace('[^\\w\\s]', '', regex=True)\n",
    "# remove nan from text\n",
    "train_data['text'] = train_data['text'].fillna('')\n",
    "test_data['text'] = test_data['text'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fabe656b-a983-4ab1-b7e9-497e2dab859e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "Best Model Accuracy: 0.8580527752502275\n",
      "Best Model Precision: 0.8146297953410058\n",
      "Best Model Recall: 0.8580527752502275\n",
      "Best Model Parameters: {'cv__max_df': 0.5, 'cv__ngram_range': (1, 2), 'lr__C': 1, 'lr__penalty': 'l2', 'lr__solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# setup CountVectorizer\n",
    "c_vectorizer = CountVectorizer(\n",
    "    stop_words='english',\n",
    "    dtype=float\n",
    ")\n",
    "\n",
    "# setup LogisticRegression\n",
    "pipeline1 = Pipeline([\n",
    "    ('cv', c_vectorizer),\n",
    "    ('lr', LogisticRegression(max_iter=10000))\n",
    "])\n",
    "\n",
    "param_grid1 = {\n",
    "    'cv__max_df': [0.5, 0.75, 1.0],\n",
    "    'cv__ngram_range': [(1, 1), (1, 2)],\n",
    "    'lr__C': [0.1, 1, 10],\n",
    "    'lr__penalty': ['l2'],\n",
    "    'lr__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "grid_search1 = GridSearchCV(pipeline1, param_grid1, cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search1.fit(train_data['text'], train_data['stars'])\n",
    "best_model1 = grid_search1.best_estimator_\n",
    "predictions = best_model1.predict(test_data['text'])\n",
    "accuracy = accuracy_score(test_data['stars'], predictions)\n",
    "precision = precision_score(test_data['stars'], predictions, average='weighted',labels=[1, 2, 3, 4, 5])\n",
    "recall = recall_score(test_data['stars'], predictions, average='weighted',labels=[1, 2, 3, 4, 5])\n",
    "print(\"Best Model Accuracy:\", accuracy)\n",
    "print(\"Best Model Precision:\", precision)\n",
    "print(\"Best Model Recall:\", recall)\n",
    "print(\"Best Model Parameters:\", grid_search1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e475ccb-00bf-4215-a804-ba8dd5535939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1728 candidates, totalling 8640 fits\n",
      "Best Model Accuracy: 0.8437973915680922\n",
      "Best Model Precision: 0.7762713244004648\n",
      "Best Model Recall: 0.8437973915680922\n"
     ]
    }
   ],
   "source": [
    "# Setup DecisionTreeClassifier\n",
    "pipeline2 = Pipeline([\n",
    "    ('cv', c_vectorizer),\n",
    "    ('dt', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "param_grid2 = {\n",
    "    'cv__max_df': [0.5, 0.75, 1.0],\n",
    "    'cv__ngram_range': [(1, 1), (1, 2)],\n",
    "    'dt__criterion': ['gini', 'entropy'],\n",
    "    'dt__max_depth': [None, 10, 20, 30],\n",
    "    'dt__min_samples_split': [2, 5, 10],\n",
    "    'dt__min_samples_leaf': [1, 2, 4],\n",
    "    'dt__max_features': [None, 'auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid_search2 = GridSearchCV(pipeline2, param_grid2, cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search2.fit(train_data['text'], train_data['stars'])\n",
    "best_model2 = grid_search2.best_estimator_\n",
    "predictions = best_model2.predict(test_data['text'])\n",
    "accuracy = accuracy_score(test_data['stars'], predictions)\n",
    "precision = precision_score(test_data['stars'], predictions, average='weighted',labels=[1, 2, 3, 4, 5])\n",
    "recall = recall_score(test_data['stars'], predictions, average='weighted',labels=[1, 2, 3, 4, 5])\n",
    "print(\"Best Model Accuracy:\", accuracy)\n",
    "print(\"Best Model Precision:\", precision)\n",
    "print(\"Best Model Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ee80781-d905-40d0-9107-372279ef8b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best Model Accuracy: 0.8528965726417955\n",
      "Best Model Precision: 0.8249335975091524\n",
      "Best Model Recall: 0.8528965726417955\n",
      "Best Model Parameters: {'cv__max_df': 0.5, 'cv__ngram_range': (1, 1), 'rf__max_depth': None, 'rf__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Setup RandomForestClassifier\n",
    "pipeline3 = Pipeline([\n",
    "    ('cv', c_vectorizer),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "param_grid3 = {\n",
    "    'cv__max_df': [0.5, 0.75, 1.0],\n",
    "    'cv__ngram_range': [(1, 1), (1, 2)],\n",
    "    'rf__n_estimators': [100],\n",
    "    #'rf__criterion': ['gini', 'entropy'], I have to remove few and use defult, cuz my computer will just run forever\n",
    "    'rf__max_depth': [None, 10, 20, 30],\n",
    "    #'rf__min_samples_split': [2, 5, 10],\n",
    "    #'rf__min_samples_leaf': [1, 2, 4],\n",
    "    #'rf__max_features': [None, 'auto', 'sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "grid_search3 = GridSearchCV(pipeline3, param_grid3, cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search3.fit(train_data['text'], train_data['stars'])\n",
    "best_model3 = grid_search3.best_estimator_\n",
    "predictions = best_model3.predict(test_data['text'])\n",
    "accuracy = accuracy_score(test_data['stars'], predictions)\n",
    "precision = precision_score(test_data['stars'], predictions, average='weighted',labels=[1, 2, 3, 4, 5])\n",
    "recall = recall_score(test_data['stars'], predictions, average='weighted',labels=[1, 2, 3, 4, 5])\n",
    "print(\"Best Model Accuracy:\", accuracy)\n",
    "print(\"Best Model Precision:\", precision)\n",
    "print(\"Best Model Recall:\", recall)\n",
    "print(\"Best Model Parameters:\", grid_search3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86bb3e20-ed26-4b87-a761-91fc11218213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "Best Model Accuracy: 0.8474370639975736\n",
      "Best Model Precision: 0.7819332918593693\n",
      "Best Model Recall: 0.8474370639975736\n",
      "Best Model Parameters: {'cv__max_df': 0.5, 'cv__ngram_range': (1, 2), 'nb__alpha': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Setup MultinomialNB\n",
    "pipeline4 = Pipeline([\n",
    "    ('cv', c_vectorizer),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "param_grid4 = {\n",
    "    'cv__max_df': [0.5, 0.75, 1.0],\n",
    "    'cv__ngram_range': [(1, 1), (1, 2)],\n",
    "    'nb__alpha': [1.0, 0.1, 0.01],\n",
    "}\n",
    "\n",
    "grid_search4 = GridSearchCV(pipeline4, param_grid4, cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search4.fit(train_data['text'], train_data['stars'])\n",
    "best_model4 = grid_search4.best_estimator_\n",
    "predictions = best_model4.predict(test_data['text'])\n",
    "accuracy = accuracy_score(test_data['stars'], predictions)\n",
    "precision = precision_score(test_data['stars'], predictions, average='weighted',labels=[1, 2, 3, 4, 5])\n",
    "recall = recall_score(test_data['stars'], predictions, average='weighted',labels=[1, 2, 3, 4, 5])\n",
    "print(\"Best Model Accuracy:\", accuracy)\n",
    "print(\"Best Model Precision:\", precision)\n",
    "print(\"Best Model Recall:\", recall)\n",
    "print(\"Best Model Parameters:\", grid_search4.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b01585-3d74-4048-b33b-ad9348d407e6",
   "metadata": {},
   "source": [
    "# The best accuracy for countvectorizer is LogisticRegression and Best Model Parameters: {'cv__max_df': 0.5, 'cv__ngram_range': (1, 2), 'lr__C': 1, 'lr__penalty': 'l2', 'lr__solver': 'liblinear'}, 85.87% (drop 0), 78.28% (with 0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5489388d-9278-47f5-9d32-156cbd142ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup CountVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    stop_words='english',\n",
    "    dtype=float\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7432544-95ec-42c5-a328-2f6791ce22bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:2072: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. <class 'float'> 'dtype' will be converted to np.float64.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Accuracy: 0.8601759175007583\n",
      "Best Model Precision: 0.816844612059923\n",
      "Best Model Recall: 0.8601759175007583\n",
      "Best Model Parameters: {'lr__C': 10, 'lr__penalty': 'l2', 'lr__solver': 'saga', 'tfidf__max_df': 0.5, 'tfidf__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "# set up LogisticRegression\n",
    "pipeline5 = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer),\n",
    "    ('lr', LogisticRegression(max_iter=10000))])\n",
    "\n",
    "# we will use same params for grid\n",
    "param_grid1 = {\n",
    "    'tfidf__max_df': [0.5, 0.75, 1.0],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'lr__C': [0.1, 1, 10],\n",
    "    'lr__penalty': ['l2'],\n",
    "    'lr__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "grid_search5 = GridSearchCV(pipeline5, param_grid1, cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search5.fit(train_data['text'], train_data['stars'])\n",
    "best_model5 = grid_search5.best_estimator_\n",
    "predictions = best_model5.predict(test_data['text'])\n",
    "accuracy = accuracy_score(test_data['stars'], predictions)\n",
    "precision = precision_score(test_data['stars'], predictions, average='weighted',labels=[1, 2, 3, 4, 5])\n",
    "recall = recall_score(test_data['stars'], predictions, average='weighted',labels=[1, 2, 3, 4, 5])\n",
    "print(\"Best Model Accuracy:\", accuracy)\n",
    "print(\"Best Model Precision:\", precision)\n",
    "print(\"Best Model Recall:\", recall)\n",
    "print(\"Best Model Parameters:\", grid_search5.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd3f2529-72f9-4ac6-a3b2-83672f2f7de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1728 candidates, totalling 8640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:2072: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. <class 'float'> 'dtype' will be converted to np.float64.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Accuracy: 0.8444040036396724\n",
      "Best Model Precision: 0.769785944424968\n",
      "Best Model Recall: 0.8444040036396724\n",
      "Best Model Parameters: {'dt__criterion': 'entropy', 'dt__max_depth': 10, 'dt__max_features': 'sqrt', 'dt__min_samples_leaf': 4, 'dt__min_samples_split': 5, 'tfidf__max_df': 0.5, 'tfidf__ngram_range': (1, 1)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# setup DecisionTreeClassifier\n",
    "pipeline6 = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer),\n",
    "    ('dt', DecisionTreeClassifier())])\n",
    "\n",
    "# we will use same params for grid\n",
    "param_grid2 = {\n",
    "    'tfidf__max_df': [0.5, 0.75, 1.0],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'dt__criterion': ['gini', 'entropy'],\n",
    "    'dt__max_depth': [None, 10, 20, 30],\n",
    "    'dt__min_samples_split': [2, 5, 10],\n",
    "    'dt__min_samples_leaf': [1, 2, 4],\n",
    "    'dt__max_features': [None, 'auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid_search6 = GridSearchCV(pipeline6, param_grid2, cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search6.fit(train_data['text'], train_data['stars'])\n",
    "best_model6 = grid_search6.best_estimator_\n",
    "predictions = best_model6.predict(test_data['text'])\n",
    "accuracy = accuracy_score(test_data['stars'], predictions)\n",
    "precision = precision_score(test_data['stars'], predictions, average='weighted',labels=[1, 2, 3, 4, 5])\n",
    "recall = recall_score(test_data['stars'], predictions, average='weighted',labels=[1, 2, 3, 4, 5])\n",
    "print(\"Best Model Accuracy:\", accuracy)\n",
    "print(\"Best Model Precision:\", precision)\n",
    "print(\"Best Model Recall:\", recall)\n",
    "print(\"Best Model Parameters:\", grid_search6.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed91bec0-10bb-4930-ad3f-cc668c8c69ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:2072: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. <class 'float'> 'dtype' will be converted to np.float64.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Accuracy: 0.851380042462845\n",
      "Best Model Precision: 0.8340121079301349\n",
      "Best Model Recall: 0.851380042462845\n",
      "Best Model Parameters: {'rf__max_depth': None, 'rf__n_estimators': 100, 'tfidf__max_df': 0.75, 'tfidf__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "# setup RandomForestClassifier\n",
    "pipeline7 = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "param_grid3 = {\n",
    "    'tfidf__max_df': [0.5, 0.75, 1.0],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'rf__n_estimators': [100],\n",
    "    #'rf__criterion': ['gini', 'entropy'], I have to remove few and use defult, cuz my computer will just run forever\n",
    "    'rf__max_depth': [None, 10, 20, 30],\n",
    "    #'rf__min_samples_split': [2, 5, 10],\n",
    "    #'rf__min_samples_leaf': [1, 2, 4],\n",
    "    #'rf__max_features': [None, 'auto', 'sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "grid_search7 = GridSearchCV(pipeline7, param_grid3, cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search7.fit(train_data['text'], train_data['stars'])\n",
    "best_model7 = grid_search7.best_estimator_\n",
    "predictions = best_model7.predict(test_data['text'])\n",
    "accuracy = accuracy_score(test_data['stars'], predictions)\n",
    "precision = precision_score(test_data['stars'], predictions, average='weighted',labels=[1, 2, 3, 4, 5])\n",
    "recall = recall_score(test_data['stars'], predictions, average='weighted',labels=[1, 2, 3, 4, 5])\n",
    "print(\"Best Model Accuracy:\", accuracy)\n",
    "print(\"Best Model Precision:\", precision)\n",
    "print(\"Best Model Recall:\", recall)\n",
    "print(\"Best Model Parameters:\", grid_search7.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c42f701b-bfa6-480b-a217-d7d36b815237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:2072: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. <class 'float'> 'dtype' will be converted to np.float64.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Accuracy: 0.8535031847133758\n",
      "Best Model Precision: 0.8122159526777399\n",
      "Best Model Recall: 0.8535031847133758\n",
      "Best Model Parameters: {'nb__alpha': 0.01, 'tfidf__max_df': 0.5, 'tfidf__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "# Setup MultinomialNB\n",
    "pipeline8 = Pipeline([\n",
    "    ('tfidf', tfidf_vectorizer),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "param_grid4 = {\n",
    "    'tfidf__max_df': [0.5, 0.75, 1.0],\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'nb__alpha': [1.0, 0.1, 0.01],\n",
    "}\n",
    "\n",
    "grid_search8 = GridSearchCV(pipeline8, param_grid4, cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search8.fit(train_data['text'], train_data['stars'])\n",
    "best_model8 = grid_search8.best_estimator_\n",
    "predictions = best_model8.predict(test_data['text'])\n",
    "accuracy = accuracy_score(test_data['stars'], predictions)\n",
    "precision = precision_score(test_data['stars'], predictions, average='weighted',labels=[1, 2, 3, 4, 5])\n",
    "recall = recall_score(test_data['stars'], predictions, average='weighted',labels=[1, 2, 3, 4, 5])\n",
    "print(\"Best Model Accuracy:\", accuracy)\n",
    "print(\"Best Model Precision:\", precision)\n",
    "print(\"Best Model Recall:\", recall)\n",
    "print(\"Best Model Parameters:\", grid_search8.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c35aef-c54d-44b4-ab02-666c78c9a2ac",
   "metadata": {},
   "source": [
    "# The best accuracy for TF-IDF is LogisticRegression and Best Model Parameters: {'lr__C': 10, 'lr__penalty': 'l2', 'lr__solver': 'liblinear', 'tfidf__max_df': 0.5, 'tfidf__ngram_range': (1, 2)}, 85.90% (dropped o) or 78.66% (with 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49da8847-776b-46e8-839f-89c7020210f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8456172277828329\n",
      "Best Model Accuracy: 0.8456172277828329\n",
      "Best Model Precision: 0.7150684959231235\n",
      "Best Model Recall: 0.8456172277828329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Extract Basic Text Features using pandas, for LogisticRegression.\n",
    "train_data['text_length'] = train_data['text'].fillna('').apply(len)\n",
    "test_data['text_length'] = test_data['text'].fillna('').apply(len)\n",
    "y_train = train_data['stars']\n",
    "y_test = test_data['stars']\n",
    "X_train_pd = train_data[['text_length']]\n",
    "X_test_pd = test_data[['text_length']]\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train_pd, y_train)\n",
    "predictions = lr_model.predict(X_test_pd)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(accuracy)\n",
    "precision = precision_score(test_data['stars'], predictions, average='weighted',labels=[1, 2, 3, 4, 5])\n",
    "recall = recall_score(test_data['stars'], predictions, average='weighted',labels=[1, 2, 3, 4, 5])\n",
    "print(\"Best Model Accuracy:\", accuracy)\n",
    "print(\"Best Model Precision:\", precision)\n",
    "print(\"Best Model Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa1c1b1-e040-44c8-b88d-1528334c8b78",
   "metadata": {},
   "source": [
    "# The accuracy for the model using length for basic text information and Logistic Regression is 84.56%(dropped 0) and 76.66% (with 0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7f003ad-aa3e-44b2-b124-147587b373ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the result predict into csv use the best model: TF-IDF x LogisticRegression\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range = (1, 2),\n",
    "    max_df = 0.5\n",
    ")\n",
    "X_train_tfidf = vectorizer.fit_transform(train_data['text'])\n",
    "X_test_tfidf = vectorizer.transform(test_data['text'])\n",
    "y_train = train_data['stars'] \n",
    "y_test = test_data['stars']\n",
    "model = LogisticRegression(max_iter=1000, penalty = 'l2', C = 10, solver = 'liblinear')\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "predictions = model.predict(X_test_tfidf)\n",
    "with open('accuracy.csv', 'w') as f:\n",
    "    f.write(str(predictions))\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "with open('accuracy.csv', 'w') as f:\n",
    "    f.write(str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf64c15-5c86-4175-a93f-fc2017a4fc56",
   "metadata": {},
   "source": [
    "# Use transformers for advance improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d8098a7-4837-42d2-a782-5a669a83eb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# refrence https://huggingface.co/docs/transformers/en/preprocessing, it took too much time for trainng. I keep the code but won't use it \n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e93af45f-a03e-42e2-bb70-24990e742c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Load data\\ntrain_data = pd.read_csv('train.csv')\\ntest_data = pd.read_csv('test.csv')\\n\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Load data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cb866e8-cf7d-4d6f-839e-88d36a379896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Initialize tokenizer\\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ba716e0-cae3-4706-a256-91fe02ec9df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Preprocess and tokenize the text\\ndef preprocess_and_tokenize(data):\\n    data[\\'text\\'] = data[\\'text\\'].str.lower().str.replace(\\'[^\\\\w\\\\s]\\', \\'\\', regex=True).fillna(\\'\\')\\n    return tokenizer(data[\\'text\\'].tolist(), truncation=True, padding=True, return_tensors=\"pt\")\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Preprocess and tokenize the text\n",
    "def preprocess_and_tokenize(data):\n",
    "    data['text'] = data['text'].str.lower().str.replace('[^\\w\\s]', '', regex=True).fillna('')\n",
    "    return tokenizer(data['text'].tolist(), truncation=True, padding=True, return_tensors=\"pt\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "766df314-5702-400b-b4ab-8cd568a85bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrain_encodings = preprocess_and_tokenize(train_data)\\ntest_encodings = preprocess_and_tokenize(test_data)\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_encodings = preprocess_and_tokenize(train_data)\n",
    "test_encodings = preprocess_and_tokenize(test_data)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "009a13fc-8f31-4b72-8403-b73f0b4e8ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Creating datasets\\ntrain_labels = torch.tensor(train_data['stars'].values)\\ntest_labels = torch.tensor(test_data['stars'].values)\\n\\ntrain_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], train_labels)\\ntest_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], test_labels)\\n\\n# Creating data loaders\\ntrain_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\\ntest_loader = DataLoader(test_dataset, batch_size=2)\\n\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Creating datasets\n",
    "train_labels = torch.tensor(train_data['stars'].values)\n",
    "test_labels = torch.tensor(test_data['stars'].values)\n",
    "\n",
    "train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], train_labels)\n",
    "test_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], test_labels)\n",
    "\n",
    "# Creating data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7adb43d4-03d6-4662-b2ce-2d9b00c46d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Load and prepare the model\\nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=6)\\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\nmodel.to(device)\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Load and prepare the model\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=6)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c15f7d76-750d-40d0-99cb-2718b3c38e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Initialize optimizer and scheduler\\noptimizer = AdamW(model.parameters(), lr=5e-5)\\nepochs = 150\\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * epochs)\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Initialize optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "epochs = 150\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * epochs)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5121a2e-c8f0-41ce-8974-08a7982f42f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel.train()\\nfor epoch in range(epochs):\\n    total_loss = 0\\n    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\\n        batch = tuple(b.to(device) for b in batch)\\n        inputs = {\\n            \\'input_ids\\': batch[0],\\n            \\'attention_mask\\': batch[1],\\n            \\'labels\\': batch[2]\\n        }\\n        optimizer.zero_grad()\\n        outputs = model(**inputs)\\n        loss = outputs.loss\\n        loss.backward()\\n        optimizer.step()\\n        scheduler.step()  \\n        total_loss += loss.item()\\n\\n    avg_loss = total_loss / len(train_loader)\\n    print(f\"Epoch {epoch+1}, Average Loss: {avg_loss}\")\\n    model.eval()\\n    '"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        inputs = {\n",
    "            'input_ids': batch[0],\n",
    "            'attention_mask': batch[1],\n",
    "            'labels': batch[2]\n",
    "        }\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()  \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}, Average Loss: {avg_loss}\")\n",
    "    model.eval()\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba782044-0d54-4443-8b4a-d75137d481f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\npredictions, true_labels = [], []\\n\\nfor batch in test_loader:\\n    batch = tuple(b.to(device) for b in batch)\\n    inputs = {\\n        'input_ids': batch[0],\\n        'attention_mask': batch[1]\\n    }\\n    with torch.no_grad():\\n        outputs = model(**inputs)\\n    \\n    logits = outputs.logits\\n    predictions.append(logits.argmax(dim=-1).cpu().numpy())\\n    true_labels.append(batch[2].cpu().numpy())\\n   \""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "predictions, true_labels = [], []\n",
    "\n",
    "for batch in test_loader:\n",
    "    batch = tuple(b.to(device) for b in batch)\n",
    "    inputs = {\n",
    "        'input_ids': batch[0],\n",
    "        'attention_mask': batch[1]\n",
    "    }\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    predictions.append(logits.argmax(dim=-1).cpu().numpy())\n",
    "    true_labels.append(batch[2].cpu().numpy())\n",
    "   ''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "905366d0-f66c-407f-b822-862b4bbc385b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Flatten lists\\npredictions = np.concatenate(predictions)\\ntrue_labels = np.concatenate(true_labels)\\n\\naccuracy = accuracy_score(true_labels, predictions)\\nprint(f\"Accuracy: {accuracy:.4f}\")\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Flatten lists\n",
    "predictions = np.concatenate(predictions)\n",
    "true_labels = np.concatenate(true_labels)\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea4cdd4-e8b8-48c4-a48c-30a1d5ef0abd",
   "metadata": {},
   "source": [
    "# Use Voting Classifier for advance improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32130f92-54bd-4375-85e4-80f1f1fd472b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.ensemble import VotingClassifier\\n\\npipe_lr = Pipeline([('vect', vectorizer), ('clf', LogisticRegression(max_iter=10000))])\\npipe_dt = Pipeline([('vect', vectorizer), ('clf', DecisionTreeClassifier())])\\npipe_rf = Pipeline([('vect', vectorizer), ('clf', RandomForestClassifier())])\\npipe_nb = Pipeline([('vect', vectorizer), ('clf', MultinomialNB())])\\n\\n# setup voting classifier\\nvoting_clf = VotingClassifier(estimators=[\\n    ('lr', pipe_lr), \\n    ('dt', pipe_dt), \\n    ('rf', pipe_rf), \\n    ('nb', pipe_nb)\\n], voting='hard')\\nvoting_clf.fit(X_train, y_train)\\npredictions = voting_clf.predict(X_test)\\naccuracy = accuracy_score(y_test, predictions)\\naccuracy\\npredictions\\n\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "pipe_lr = Pipeline([('vect', vectorizer), ('clf', LogisticRegression(max_iter=10000))])\n",
    "pipe_dt = Pipeline([('vect', vectorizer), ('clf', DecisionTreeClassifier())])\n",
    "pipe_rf = Pipeline([('vect', vectorizer), ('clf', RandomForestClassifier())])\n",
    "pipe_nb = Pipeline([('vect', vectorizer), ('clf', MultinomialNB())])\n",
    "\n",
    "# setup voting classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('lr', pipe_lr), \n",
    "    ('dt', pipe_dt), \n",
    "    ('rf', pipe_rf), \n",
    "    ('nb', pipe_nb)\n",
    "], voting='hard')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "predictions = voting_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "accuracy\n",
    "predictions\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b44d7f-ef50-4a13-8065-1fdf2a894297",
   "metadata": {},
   "source": [
    "# Q1 Using TF-IDF x (logistic regression,DecisionTree Classifier,RandomForest Classifier,MultinomialNB) for classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0f2f1b12-4156-44e1-aadb-822200042272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.17      0.28        46\n",
      "           2       0.38      0.07      0.12        44\n",
      "           3       0.50      0.15      0.23        98\n",
      "           4       0.49      0.18      0.27       321\n",
      "           5       0.88      0.99      0.93      2788\n",
      "\n",
      "    accuracy                           0.86      3297\n",
      "   macro avg       0.58      0.31      0.37      3297\n",
      "weighted avg       0.82      0.86      0.83      3297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range = (1, 2),\n",
    "    max_df = 0.5\n",
    ")\n",
    "X_train_tfidf = vectorizer.fit_transform(train_data['text'])\n",
    "X_test_tfidf = vectorizer.transform(test_data['text'])\n",
    "y_train = train_data['stars'] \n",
    "y_test = test_data['stars']\n",
    "model = LogisticRegression(max_iter=1000, penalty = 'l2', C = 10, solver = 'liblinear')\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "predictions = model.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3356c2d3-66fd-4a12-8064-bd68cdea9daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.00      0.00        46\n",
      "           2       0.00      0.00      0.00        44\n",
      "           3       0.00      0.00      0.00        98\n",
      "           4       0.00      0.00      0.00       321\n",
      "           5       0.85      1.00      0.92      2788\n",
      "\n",
      "    accuracy                           0.84      3297\n",
      "   macro avg       0.37      0.20      0.18      3297\n",
      "weighted avg       0.73      0.84      0.77      3297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DecisionTree Classifier\n",
    "model = DecisionTreeClassifier(criterion='entropy', max_depth=10, max_features='sqrt', min_samples_leaf = 4, min_samples_split= 5)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "predictions = model.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(classification_report(y_test,predictions, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e3fc85ed-05f7-4e96-93bf-8f2e1dedf505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.04      0.08        46\n",
      "           2       1.00      0.02      0.04        44\n",
      "           3       0.57      0.04      0.08        98\n",
      "           4       0.86      0.04      0.07       321\n",
      "           5       0.85      1.00      0.92      2788\n",
      "\n",
      "    accuracy                           0.85      3297\n",
      "   macro avg       0.79      0.23      0.24      3297\n",
      "weighted avg       0.84      0.85      0.79      3297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RandomForest Classifier\n",
    "model = RandomForestClassifier(max_depth = None, n_estimators=100)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "predictions = model.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(classification_report(y_test,predictions, zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "70533d5a-75d7-422e-8967-a03b68811a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.26      0.39        46\n",
      "           2       1.00      0.02      0.04        44\n",
      "           3       0.45      0.10      0.17        98\n",
      "           4       0.48      0.12      0.20       321\n",
      "           5       0.87      0.99      0.93      2788\n",
      "\n",
      "    accuracy                           0.86      3297\n",
      "   macro avg       0.72      0.30      0.35      3297\n",
      "weighted avg       0.82      0.86      0.82      3297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MultinomialNB\n",
    "model = MultinomialNB(alpha=0.01)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "predictions = model.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(classification_report(y_test,predictions, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d00db6-dc22-4bbe-8886-337fa6605b2b",
   "metadata": {},
   "source": [
    "# How does the performance of your model vary across different classes? Analyze and discuss your observations regarding the precision and recall metrics for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db7a114-29cc-49d5-bb0b-6a7fc8e91bc0",
   "metadata": {},
   "source": [
    "#### Across all models, there's a clear trend: performance on classes 1 through 4 is substantially lower than on class 5. This discrepancy is most likely due to class imbalance, with class 5 significantly dominating the dataset. The high performance on class 5 skews the overall accuracy, making the models appear more effective than they actually are for the minority classes. For Logistic Regression, the precision and recall for class 5 are at a high level; however, classes 1-4 exhibit much lower scores (a similar problem is observed with the other three models). Both the Decision Tree and Random Forest classifiers are affected by class imbalance and exhibit bias issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5231d64c-f524-4645-9de6-5c34cea761a8",
   "metadata": {},
   "source": [
    "# Considering your analysis, how would you recommend using this model in a real- world application? Discuss any limitations or considerations that should be taken into account."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bca500-52bc-4541-99c1-20e1ecf5b7ac",
   "metadata": {},
   "source": [
    "#### For real-world applications, understanding the content during preprocessing is crucial before developing any model. We need to be mindful of the model's performance in special contexts, such as detecting toxic comments (where recall is important) or email spam detection (where precision is prioritized). Continuous evaluation and updating of our datasets and models, informed by a user feedback loop and performance monitoring, are essential for maintaining relevance and effectiveness. \n",
    "\n",
    "#### \r\n",
    "Among the limitations or considerations to be mindful of, bias and fairness stand out. Our models may inadvertently reflect or amplify biases present in the training data. Techniques for bias mitigation and fairness-aware modeling may be necessary to address these concerns. While Logistic Regression models are more interpretable than some complex models, they may still not provide sufficient insight into the reasons behind specific predictions, especially for non-technical users\n",
    "\n",
    "#### \r\n",
    "\r\n",
    "Furthermore, the CountVectorizer approach may struggle with new, unseen words, potentially affecting the model's performance on new data. Exploring techniques like word embeddings or transfer learning models, which can generalize better from known to unknown words, can offer improvem as using different embeddingsa (in here I switch to TF-IDF).rea."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15c1d10-03c0-47bf-81e7-5b2079f3ccec",
   "metadata": {},
   "source": [
    "# Analyze your data to address the previously identified accuracy issues. Describe your method to address this issue, implement it in code and retrain a classifier, and assess any improvements or ongoing challenges. Your evaluation will be based on your method's appropriateness, not the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452231b7-5fb1-4eea-94e5-fa74427491eb",
   "metadata": {},
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207d9557-9055-4da0-a775-09c8ac74d8ec",
   "metadata": {},
   "source": [
    "#### In this section, I explored two methods for improvements: switching to a transformer model and using a Voting Classifier. The training process for the transformer was halted due to excessive time consumption and suboptimal GPU performance. Additionally, I implemented a Voting Classifier. Typically, this approach allows for the combination of multiple models, which can compensate for each model's weaknesses. For instance, some methods might underperform for a particular class, while others excel. By assigning different weights to each model, we can optimize performance given the current dataset constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28808bc2-9cbd-47ab-a921-6f9be35b4d97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
